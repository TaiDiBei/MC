{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2783509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第四问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb96546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 针对问题四，附件四给出部分甲骨文图像及其对应的简体中文，我们建立inception_v3分类模型，通过训练数据对模型进行微调。\n",
    "# 将得到的在甲骨文文字识别任务上微调后的inception_v3模型对测试集数据进行文字识别。\n",
    "# 将识别结果保存，写入论文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  # 导入json模块，用于处理JSON格式的数据\n",
    "import os  # 导入os模块，用于处理文件和目录路径\n",
    "\n",
    "import torch  # 导入PyTorch深度学习框架\n",
    "import torch.nn as nn  # 导入torch.nn模块，用于构建神经网络\n",
    "import torchvision.models as models  # 导入torchvision.models模块，包含了一些经典的深度学习模型\n",
    "from torchvision import transforms  # 导入transforms模块，用于数据预处理\n",
    "from torch.utils.data import DataLoader, Dataset  # 导入DataLoader和Dataset类，用于加载数据\n",
    "from PIL import Image  # 导入Image模块，用于图像处理\n",
    "from sklearn.metrics import f1_score  # 导入f1_score函数，用于评估模型性能\n",
    "from torch.optim.lr_scheduler import StepLR  # 导入StepLR类，用于学习率调度\n",
    "from tqdm import tqdm  # 导入tqdm模块，用于显示进度条\n",
    "\n",
    "# 检查CUDA是否可用，并设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# 构建自定义数据集\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths  # 文件路径列表\n",
    "        self.labels = labels  # 标签列表\n",
    "        self.transform = transform  # 数据预处理的转换操作\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)  # 返回数据集大小\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.file_paths[idx]).convert('RGB')  # 读取图像并转换为RGB模式\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)  # 转换标签为张量\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # 应用数据预处理的转换操作\n",
    "\n",
    "        return image, label  # 返回图像和标签的元组\n",
    "\n",
    "\n",
    "# 超参数\n",
    "batch_size = 32  # 批量大小\n",
    "num_epochs = 50  # 迭代次数\n",
    "learning_rate = 0.001  # 学习率\n",
    "num_classes = 76  # 类别数，假设有10个类别\n",
    "\n",
    "# 转换图像\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # 调整图像大小为299x299像素\n",
    "    transforms.ToTensor(),  # 转换图像为张量\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 归一化图像\n",
    "])\n",
    "\n",
    "train_file_dir = \"q4_data/train/image\"  # 训练数据文件夹路径\n",
    "train_file_paths = os.listdir(train_file_dir)  # 获取文件夹下的所有文件名\n",
    "# 给每个文件路径添加文件夹路径\n",
    "train_file_paths = [os.path.join(train_file_dir, file_name) for file_name in train_file_paths]\n",
    "# 从JSON文件中读取数据\n",
    "with open(\"q4_train_inception.json\", \"r\") as json_file:\n",
    "    train_labels = json.load(json_file)  # 读取JSON文件中的标签数据\n",
    "# 数据加载\n",
    "train_dataset = CustomDataset(train_file_paths, train_labels, transform=transform)  # 创建训练数据集\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  # 创建训练数据加载器\n",
    "\n",
    "# 加载预训练的InceptionV3模型\n",
    "model = models.inception_v3(pretrained=True)  # 加载预训练的InceptionV3模型\n",
    "model.aux_logits = False  # 禁用辅助输出\n",
    "\n",
    "# 修改最后一层全连接层以适应多标签分类任务\n",
    "num_ftrs = model.fc.in_features  # 获取全连接层的输入特征数\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),  # 添加全连接层\n",
    "    nn.ReLU(inplace=True),  # 添加ReLU激活函数\n",
    "    nn.Linear(512, num_classes),  # 添加全连接层\n",
    "    nn.Sigmoid()  # 多标签分类使用Sigmoid激活函数\n",
    ")\n",
    "\n",
    "model = model.to(device)  # 将模型移动到设备上\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCELoss()  # 定义二分类交叉熵损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # 定义Adam优化器\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)  # 设置学习率调度器\n",
    "\n",
    "# 训练模型\n",
    "total_step = len(train_loader)  # 获取训练批次数\n",
    "for epoch in tqdm(range(num_epochs)):  # 迭代训练数据集\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    for i, (images, labels) in enumerate(tqdm(train_loader)):  # 迭代每个批次的数据\n",
    "        images = images.to(device)  # 将图像数据移动到设备上\n",
    "        labels = labels.to(device)  # 将标签数据移动到设备上\n",
    "        # 前向传播\n",
    "        outputs = model(images)  # 输入图像并获取模型输出\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)  # 计算损失\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()  # 梯度清零\n",
    "        loss.backward()  # 反向传播计算梯度\n",
    "        optimizer.step()  # 更新模型参数\n",
    "\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "\n",
    "    # 调整学习率\n",
    "    scheduler.step()\n",
    "\n",
    "    # 评估循环\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        # 初始化预测和标签列表\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        for images, labels in tqdm(train_loader):  # 迭代每个批次的数据\n",
    "            images = images.to(device)  # 将图像数据移动到设备上\n",
    "            labels = labels.to(device)  # 将标签数据移动到设备上\n",
    "            # 前向传播\n",
    "            outputs = model(images)  # 输入图像并获取模型输出\n",
    "            predicted = outputs > 0.5  # 预测结果大于0.5为正类，否则为负类\n",
    "            # 计算准确率\n",
    "            correct_predictions += (predicted == labels.byte()).all(1).sum().item()  # 统计预测正确的数量\n",
    "            total_predictions += labels.size(0)  # 统计总样本数量\n",
    "            # 收集预测和真实标签\n",
    "            all_preds.extend(predicted.cpu().numpy())  # 将预测结果添加到预测列表中\n",
    "            all_labels.extend(labels.cpu().numpy())  # 将真实标签添加到标签列表中\n",
    "        accuracy = correct_predictions / total_predictions  # 计算准确率\n",
    "        f1 = f1_score(all_labels, all_preds, average='micro')  # 计算F1分数\n",
    "        print('Epoch [{}/{}], Accuracy: {:.4f}, F1 Score: {:.4f}'.format(epoch + 1, num_epochs, accuracy, f1))\n",
    "\n",
    "    # 保存模型\n",
    "    torch.save(model.state_dict(), f'ckpt/inceptionv3_ft_{epoch}_f1_{f1:.4f}_acc_{accuracy:.4f}.pth')  # 保存模型参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f5855",
   "metadata": {},
   "outputs": [],
   "source": [
    "上述代码需要加以解释：赛事方提供的附件四中训练集有40617张甲骨文图像\n",
    "为了满足inception模型的输入，我们对数据进行预处理，将每一个文字的作为一个类别\n",
    "一共有76类，我们建立了一个python列表，里面存储了40617张甲骨文图像的labels\n",
    "数据预处理代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  # 导入json模块，用于处理JSON格式的数据\n",
    "import os  # 导入os模块，用于处理文件和目录路径\n",
    "import re  # 导入re模块，用于正则表达式匹配\n",
    "import shutil  # 导入shutil模块，用于文件操作\n",
    "\n",
    "from tqdm import tqdm  # 导入tqdm模块，用于显示进度条\n",
    "\n",
    "\n",
    "def find_number_before_dash(string):\n",
    "    \"\"\"\n",
    "    在字符串中查找连接符“-”前面的数字并返回。\n",
    "    \"\"\"\n",
    "    match = re.search(r'\\d+(?=-)', string)  # 使用正则表达式查找数字\n",
    "    if match:\n",
    "        return int(match.group())  # 返回匹配到的数字\n",
    "    else:\n",
    "        return None  # 如果未找到匹配的数字，则返回None\n",
    "\n",
    "\n",
    "path = \"q4_data/train/image\"  # 图像文件夹路径\n",
    "txt_list = os.listdir(path)  # 获取文件夹中的文件列表\n",
    "# 创建包含 40617 个列表的列表，每个列表长度为 76\n",
    "nested_list = [[0] * 76 for _ in range(40617)]  # 创建嵌套列表并初始化为0\n",
    "tem = 0  # 临时变量，用于记录嵌套列表的索引\n",
    "for tl in tqdm(txt_list):  # 遍历文件列表并显示进度条\n",
    "    result = find_number_before_dash(tl)  # 调用函数获取文件名中的数字\n",
    "    nested_list[tem][result - 1] = 1  # 在嵌套列表中设置对应位置的值为1\n",
    "    tem = tem + 1  # 更新临时变量\n",
    "\n",
    "# 将嵌套列表保存为 JSON 文件\n",
    "with open(\"q4_train_inception.json\", \"w\") as json_file:\n",
    "    json.dump(nested_list, json_file)  # 将嵌套列表写入JSON文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d32d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "利用我们预处理后的数据，在inception模型上训练11个epoch后，在训练集上，模型准确率达到99.4%，F1值达到99.6%\n",
    "接下来，我们利用训练好的inception模型对附件四甲骨文原始图像进行文字自动识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97fbcda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在利用inception识别文字之前，我们先对附件四图像预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  # 导入json模块，用于处理JSON格式的数据\n",
    "import os  # 导入os模块，用于处理文件和目录路径\n",
    "\n",
    "import numpy as np  # 导入numpy模块，用于数值计算\n",
    "import torch  # 导入PyTorch深度学习库\n",
    "import torch.nn as nn  # 导入PyTorch神经网络模块\n",
    "import torchvision.models as models  # 导入PyTorch视觉模型\n",
    "from torchvision import transforms  # 导入transforms模块，用于图像处理\n",
    "from torch.utils.data import DataLoader, Dataset  # 导入DataLoader和Dataset类，用于加载数据\n",
    "from PIL import Image  # 导入PIL库，用于图像处理\n",
    "from tqdm import tqdm  # 导入tqdm模块，用于显示进度条\n",
    "\n",
    "# 检查CUDA是否可用，并设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 构建自定义数据集\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_paths, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.file_paths[idx]).convert('RGB')  # 打开图像并转换为RGB格式\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # 应用图像变换\n",
    "\n",
    "        return image\n",
    "\n",
    "# 转换图像\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # 调整图像大小为299x299\n",
    "    transforms.ToTensor(),  # 将图像转换为Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 标准化图像\n",
    "])\n",
    "\n",
    "test_file_dir = \"test_image\"  # 测试图像文件夹路径\n",
    "test_file_paths = [os.path.join(test_file_dir, file_name) for file_name in os.listdir(test_file_dir)]  # 获取测试图像文件路径列表\n",
    "\n",
    "# 数据加载\n",
    "test_dataset = CustomDataset(test_file_paths, transform=transform)  # 创建测试数据集\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)  # 创建测试数据加载器，批大小为1，不打乱顺序\n",
    "\n",
    "# 加载预训练的InceptionV3模型\n",
    "model = models.inception_v3(pretrained=False)  # 加载预训练的InceptionV3模型\n",
    "model.aux_logits = False  # 禁用辅助输出\n",
    "\n",
    "# 修改最后一层全连接层以适应多标签分类任务\n",
    "num_ftrs = model.fc.in_features  # 获取全连接层输入特征数量\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),  # 添加全连接层（1）\n",
    "    nn.ReLU(inplace=True),  # 添加ReLU激活函数\n",
    "    nn.Linear(512, 76),  # 添加全连接层（2），输出76个标签\n",
    "    nn.Sigmoid()  # 多标签分类使用Sigmoid激活函数\n",
    ")\n",
    "\n",
    "# 加载微调后的模型权重\n",
    "model_path = 'ckpt/inceptionv3_ft_10_f1_0.9962_acc_0.9940.pth'  # 模型权重文件路径\n",
    "model.load_state_dict(torch.load(model_path))  # 加载模型权重\n",
    "model = model.to(device)  # 将模型移动到设备上\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 使用模型进行预测\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader):  # 遍历测试数据加载器并显示进度条\n",
    "        images = images.to(device)  # 将图像移动到设备上\n",
    "        outputs = model(images)  # 前向传播\n",
    "        predicted = outputs > 0.5  # 使用阈值 0.5 来确定标签\n",
    "    print(predicted)  # 打印预测结果\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
