{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "367e5ab9-67aa-483a-9c9f-5136dc78d7eb",
   "metadata": {},
   "source": [
    "# 导入相关的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79062276-dc6a-4b35-91af-8c367c322db3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c79161-8ced-4098-b9ec-6c93a6fc02f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec38c62-08e9-489c-b1bc-493218faf119",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    '''\n",
    "    加载训练集和测试集数据\n",
    "    :param path: 数据所在文件夹路径\n",
    "    :return: 训练集数据和标签，测试集数据和文件名列表\n",
    "    '''\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    test_data = []\n",
    "    test_filenames = []\n",
    "    for filename in os.listdir(path):\n",
    "        # 训练集\n",
    "        if 'train' in filename:\n",
    "            with open(os.path.join(path, filename), 'rb') as f:\n",
    "                data = np.load(f)\n",
    "                train_data.append(data['arr_0'])\n",
    "                train_label.append(data['arr_1'])\n",
    "        # 测试集\n",
    "        elif 'test' in filename:\n",
    "            with open(os.path.join(path, filename), 'rb') as f:\n",
    "                data = np.load(f)\n",
    "                test_data.append(data['arr_0'])\n",
    "                test_filenames.append(data['arr_1'])\n",
    "    return np.concatenate(train_data), np.concatenate(train_label), np.concatenate(test_data), test_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b074bd-014f-4801-858f-34b720ff7f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5b590-07c2-4278-9488-2356b80264f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_feature(img):\n",
    "    '''\n",
    "    图像预处理和特征提取\n",
    "    :param img: 输入图像\n",
    "    :return: 预处理后的图像和特征\n",
    "    '''\n",
    "    # 灰度化\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 自适应二值化\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    # 提取轮廓\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    # 计算图像面积\n",
    "    img_area = img.shape[0] * img.shape[1]\n",
    "    # 只保留面积大于0.5%图像面积的轮廓\n",
    "    contours = [c for c in contours if cv2.contourArea(c) > 0.005 * img_area]\n",
    "    # 计算每个轮廓的最小外接矩形\n",
    "    rects = [cv2.boundingRect(c) for c in contours]\n",
    "    # 提取特征\n",
    "    features = []\n",
    "    for rect in rects:\n",
    "        x, y, w, h = rect\n",
    "        roi = img[y:y + h, x:x + w]\n",
    "        # 缩放大小为32x32\n",
    "        roi = cv2.resize(roi, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "        # 将图像转换为一维向量\n",
    "        roi = roi.reshape(1, -1)\n",
    "        # 归一化\n",
    "        roi = roi / 255.0\n",
    "        # 添加到特征列表中\n",
    "        features.append(roi)\n",
    "    return thresh, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e410f3-3221-4e27-afd0-dfeb06510e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de73e605-04dd-4bb0-b191-f8fd393a6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_data, train_label, test_data, test_filenames):\n",
    "    '''\n",
    "    训练和评估模型\n",
    "    :param train_data: 训练集数据\n",
    "    :param train_label: 训练集标签\n",
    "    :param test_data: 测试集数据\n",
    "    :param test_filenames: 测试集文件名列表\n",
    "    :return: 预测结果和评估报告\n",
    "    '''\n",
    "    # 拆分训练集和验证集\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_data, train_label, test_size=0.2, random_state=42)\n",
    "    # 定义模型，使用SVM分类器\n",
    "    model = SVC(C=1.0, kernel='linear', gamma='auto')\n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "    # 在验证集上评估模型\n",
    "    y_pred = model.predict(X_val)\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    # 在测试集上进行预测\n",
    "    y_pred = model.predict(test_data)\n",
    "    # 将预测结果保存到Excel文件中\n",
    "    df = pd.DataFrame({'file_name': test_filenames, 'predict': y_pred})\n",
    "    df.to_excel('Test_results.xlsx', index=False)\n",
    "    return y_pred, classification_report(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4560e6-f1e3-4b22-bca4-a7b93a4eb474",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ce41fb-56b8-447d-afe4-672c8d4c4585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 加载数据\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_data, train_label, test_data, test_filenames \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Datasets/4_Recognize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 31\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     29\u001b[0m             test_data\u001b[38;5;241m.\u001b[39mappend(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_0\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     30\u001b[0m             test_filenames\u001b[38;5;241m.\u001b[39mappend(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(train_data), np\u001b[38;5;241m.\u001b[39mconcatenate(train_label), np\u001b[38;5;241m.\u001b[39mconcatenate(test_data), test_filenames\n",
      "\u001b[1;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "train_data, train_label, test_data, test_filenames = load_data('./Datasets/4_Recognize')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98025a-459e-4a43-8695-8305561489cb",
   "metadata": {},
   "source": [
    "# 预处理和提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67cfb49a-562c-4d01-a3ea-c3aa4284b014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m test_data_preprocessed \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m test_features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(test_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m      5\u001b[0m     img \u001b[38;5;241m=\u001b[39m test_data[i]\n\u001b[0;32m      6\u001b[0m     thresh, features \u001b[38;5;241m=\u001b[39m preprocess_feature(img)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data_preprocessed = []\n",
    "test_features = []\n",
    "for i in range(test_data.shape[0]):\n",
    "    img = test_data[i]\n",
    "    thresh, features = preprocess_feature(img)\n",
    "    test_data_preprocessed.append(thresh)\n",
    "    test_features.append(features)\n",
    "test_data_preprocessed = np.array(test_data_preprocessed)\n",
    "test_features = np.concatenate(test_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1401bb8-de74-465d-8769-8015def99495",
   "metadata": {},
   "source": [
    "# 训练和评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115cbcc5-34a9-495b-a9ca-0f5d8878edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred, report = train_and_evaluate(train_data, train_label, test_features, test_filenames)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
