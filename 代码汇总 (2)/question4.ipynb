{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2783509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第四问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb96546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 针对问题四，附件四给出部分甲骨文图像及其对应的简体中文，我们建立inception_v3分类模型，通过训练数据对模型进行微调。\n",
    "# 将得到的在甲骨文文字识别任务上微调后的inception_v3模型对测试集数据进行文字识别。\n",
    "# 将识别结果保存，写入论文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception model 训练代码：\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 检查CUDA是否可用，并设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# 构建自定义数据集\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.file_paths[idx]).convert('RGB')\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# 超参数\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "num_classes = 76  # 假设有10个类别\n",
    "\n",
    "# 转换图像\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_file_dir = \"q4_data/train/image\"\n",
    "train_file_paths = os.listdir(train_file_dir)\n",
    "# 给每个文件路径添加文件夹路径\n",
    "train_file_paths = [os.path.join(train_file_dir, file_name) for file_name in train_file_paths]\n",
    "# 从JSON文件中读取数据\n",
    "with open(\"q4_train_inception.json\", \"r\") as json_file:\n",
    "    train_labels = json.load(json_file)\n",
    "# 数据加载\n",
    "train_dataset = CustomDataset(train_file_paths, train_labels, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 加载预训练的InceptionV3模型\n",
    "model = models.inception_v3(pretrained=True)\n",
    "model.aux_logits = False  # 禁用辅助输出\n",
    "# # 冻结模型参数\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# 修改最后一层全连接层以适应多标签分类任务\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(512, num_classes),\n",
    "    nn.Sigmoid()  # 多标签分类使用Sigmoid激活函数\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 学习率调度器\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# 训练模型\n",
    "total_step = len(train_loader)\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "\n",
    "    # 调整学习率\n",
    "    scheduler.step()\n",
    "\n",
    "    # 评估循环\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 初始化预测和标签列表\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "            predicted = outputs > 0.5\n",
    "            # 计算准确率\n",
    "            correct_predictions += (predicted == labels.byte()).all(1).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "            # 收集预测和真实标签\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "        print('Epoch [{}/{}], Accuracy: {:.4f}, F1 Score: {:.4f}'.format(epoch + 1, num_epochs, accuracy, f1))\n",
    "\n",
    "    # 保存模型\n",
    "    torch.save(model.state_dict(), f'ckpt/inceptionv3_ft_{epoch}_f1_{f1:.4f}_acc_{accuracy:.4f}.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f5855",
   "metadata": {},
   "outputs": [],
   "source": [
    "上述代码需要加以解释：赛事方提供的附件四中训练集有40617张甲骨文图像\n",
    "为了满足inception模型的输入，我们对数据进行预处理，将每一个文字的作为一个类别\n",
    "一共有76类，我们建立了一个python列表，里面存储了40617张甲骨文图像的labels\n",
    "数据预处理代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def find_number_before_dash(string):\n",
    "    match = re.search(r'\\d+(?=-)', string)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "path = \"q4_data/train/image\"\n",
    "txt_list = os.listdir(path)\n",
    "# 创建包含 40617 个列表的列表，每个列表长度为 76\n",
    "nested_list = [[0] * 76 for _ in range(40617)]\n",
    "tem = 0\n",
    "for tl in tqdm(txt_list):\n",
    "    result = find_number_before_dash(tl)\n",
    "    nested_list[tem][result - 1] = 1\n",
    "    tem = tem + 1\n",
    "\n",
    "# 将嵌套列表保存为 JSON 文件\n",
    "with open(\"q4_train_inception.json\", \"w\") as json_file:\n",
    "    json.dump(nested_list, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d32d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "利用我们预处理后的数据，在inception模型上训练11个epoch后，在训练集上，模型准确率达到99.4%，F1值达到99.6%\n",
    "接下来，我们利用训练好的inception模型对附件四甲骨文原始图像进行文字自动识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97fbcda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在利用inception识别文字之前，我们先对附件四图像预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ce237d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用第二问训练好的yolo，我们将附件四的五十张图像进行甲骨文的自动识别与分割\n",
    "# 将自动识别、分割后的结果保存下来进行文字识别\n",
    "# 文字识别代码如下：\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 检查CUDA是否可用，并设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# 构建自定义数据集\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_paths, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.file_paths[idx]).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "# 转换图像\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_file_dir = \"test_image\"# 将需要预测的图像放在此文件夹\n",
    "test_file_path = os.listdir(test_file_dir)\n",
    "# 给每个文件路径添加文件夹路径\n",
    "test_file_paths = [os.path.join(test_file_dir, file_name) for file_name in test_file_path]\n",
    "# 数据加载\n",
    "test_dataset = CustomDataset(test_file_paths,transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 加载预训练的InceptionV3模型\n",
    "model = models.inception_v3(pretrained=False)\n",
    "model.aux_logits = False  # 禁用辅助输出\n",
    "\n",
    "# 修改最后一层全连接层以适应多标签分类任务\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(512, 76),\n",
    "    nn.Sigmoid()  # 多标签分类使用Sigmoid激活函数\n",
    ")\n",
    "# 加载微调后的模型权重\n",
    "model_path = 'ckpt/inceptionv3_ft_10_f1_0.9962_acc_0.9940.pth'  # 替换为你的模型权重文件路径\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        predicted = outputs > 0.5  # 使用阈值 0.5 来确定标签\n",
    "    print(predicted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test1] *",
   "language": "python",
   "name": "conda-env-test1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
